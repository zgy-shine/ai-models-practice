{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c16b4f-9efe-4f5f-ad63-9d66e9ddec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os \n",
    "import dashscope\n",
    "from dashscope.api_entities.dashscope_response import Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f7fa1-6c16-481a-ab87-44fc51125875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)              # 应该能输出版本号\n",
    "print(hasattr(torch.nn, 'Module'))    # 应该输出 True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4707371-cdf4-4447-ac55-02c3721b5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "\n",
    "model_dir = snapshot_download(\n",
    "    repo_id='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',        # Hub 上的模型标识\n",
    "    cache_dir='/Users/zengguangyun/Desktop/data/大模型课程资料/autodl-tmp/models'  # 本地存储根目录\n",
    ")\n",
    "print(f\"模型已下载到：{model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2a3de-90cf-4750-8751-00fad978f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)                  # 打印版本号\n",
    "print(torch.backends.mps.is_available())  # True 表示能用 MPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b3ae1-f323-4941-bc84-415975a14bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/Users/zengguangyun/Desktop/data/大模型课程资料/autodl-tmp/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# 先确定用哪个设备\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# 加载模型（不传 device_map）\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "model.to(device)  # 搬到 MPS 或 CPU\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"帮我写一个二分查找法\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\",   \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000\n",
    ")\n",
    "# 切掉输入部分再解码\n",
    "response_ids = generated_ids[0][ inputs.input_ids.shape[-1]: ]\n",
    "print(tokenizer.decode(response_ids, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36558f03-d4ff-4e1e-8923-944ac2c4bf05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}